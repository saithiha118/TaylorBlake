{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "try:\n",
    "    sw = stopwords.words(\"english\")\n",
    "except:\n",
    "    from nltk import download as nltkdl\n",
    "    nltkdl('stopwords')\n",
    "    sw =  stopwords.words(\"english\")\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT party, text \n",
    "                            FROM conventions\n",
    "                            ''')\n",
    "convention_data=[]\n",
    "for row in query_results :\n",
    "    \n",
    "    party=row[0]\n",
    "    text=row[1]\n",
    "    \n",
    "    text=text.lower()\n",
    "    text=text.replace('\\n',' ')\n",
    "    for punct in punctuation:\n",
    "        text=text.replace(punct,'')\n",
    "    \n",
    "    words=text.split()\n",
    "    convention_dict={'party':party, 'words':words}\n",
    "    convention_data.append(convention_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'party': 'Republican', 'words': ['to', 'any', 'foreign', 'prince']},\n",
       " {'party': 'Democratic', 'words': ['reproductive', 'justice']},\n",
       " {'party': 'Democratic',\n",
       "  'words': ['our',\n",
       "   'mission',\n",
       "   'is',\n",
       "   'to',\n",
       "   'fight',\n",
       "   'for',\n",
       "   'a',\n",
       "   'future',\n",
       "   'equal',\n",
       "   'to',\n",
       "   'the',\n",
       "   'ideals',\n",
       "   'of',\n",
       "   'our',\n",
       "   'founders',\n",
       "   'our',\n",
       "   'hopes',\n",
       "   'for',\n",
       "   'our',\n",
       "   'children',\n",
       "   'and',\n",
       "   'sacrifices',\n",
       "   'of',\n",
       "   'our',\n",
       "   'veterans',\n",
       "   'our',\n",
       "   'brave',\n",
       "   'men',\n",
       "   'and',\n",
       "   'women',\n",
       "   'in',\n",
       "   'uniform',\n",
       "   'and',\n",
       "   'their',\n",
       "   'families']},\n",
       " {'party': 'Democratic',\n",
       "  'words': ['as',\n",
       "   'black',\n",
       "   'americans',\n",
       "   'standing',\n",
       "   'on',\n",
       "   'native',\n",
       "   'land',\n",
       "   'we',\n",
       "   'probably',\n",
       "   'represent',\n",
       "   'oregon',\n",
       "   'the',\n",
       "   'dual',\n",
       "   'viruses',\n",
       "   'covid19',\n",
       "   'and',\n",
       "   'racism',\n",
       "   'laid',\n",
       "   'bare',\n",
       "   'on',\n",
       "   'equal',\n",
       "   'healthcare',\n",
       "   'access',\n",
       "   'and',\n",
       "   'deaths',\n",
       "   'in',\n",
       "   'communities',\n",
       "   'of',\n",
       "   'color']},\n",
       " {'party': 'Democratic',\n",
       "  'words': ['joeâ€™s',\n",
       "   'purpose',\n",
       "   'has',\n",
       "   'always',\n",
       "   'driven',\n",
       "   'him',\n",
       "   'forward',\n",
       "   'his',\n",
       "   'strength',\n",
       "   'of',\n",
       "   'will',\n",
       "   'is',\n",
       "   'unstoppable',\n",
       "   'and',\n",
       "   'his',\n",
       "   'faith',\n",
       "   'is',\n",
       "   'unshakable',\n",
       "   'because',\n",
       "   'itâ€™s',\n",
       "   'not',\n",
       "   'in',\n",
       "   'politicians',\n",
       "   'or',\n",
       "   'political',\n",
       "   'parties',\n",
       "   'or',\n",
       "   'even',\n",
       "   'in',\n",
       "   'himself',\n",
       "   'itâ€™s',\n",
       "   'in',\n",
       "   'the',\n",
       "   'providence',\n",
       "   'of',\n",
       "   'god',\n",
       "   'his',\n",
       "   'faith',\n",
       "   'is',\n",
       "   'in',\n",
       "   'you',\n",
       "   'in',\n",
       "   'us',\n",
       "   'yes',\n",
       "   'so',\n",
       "   'many',\n",
       "   'classrooms',\n",
       "   'are',\n",
       "   'quiet',\n",
       "   'right',\n",
       "   'now',\n",
       "   'the',\n",
       "   'playgrounds',\n",
       "   'are',\n",
       "   'still',\n",
       "   'but',\n",
       "   'if',\n",
       "   'you',\n",
       "   'listen',\n",
       "   'closely',\n",
       "   'you',\n",
       "   'can',\n",
       "   'hear',\n",
       "   'the',\n",
       "   'sparks',\n",
       "   'of',\n",
       "   'change',\n",
       "   'in',\n",
       "   'the',\n",
       "   'air',\n",
       "   'across',\n",
       "   'this',\n",
       "   'country',\n",
       "   'educators',\n",
       "   'parents',\n",
       "   'first',\n",
       "   'responders',\n",
       "   'americans',\n",
       "   'of',\n",
       "   'all',\n",
       "   'walks',\n",
       "   'of',\n",
       "   'life',\n",
       "   'are',\n",
       "   'putting',\n",
       "   'their',\n",
       "   'shoulders',\n",
       "   'back',\n",
       "   'fighting',\n",
       "   'for',\n",
       "   'each',\n",
       "   'other',\n",
       "   'we',\n",
       "   'havenâ€™t',\n",
       "   'given',\n",
       "   'up',\n",
       "   'we',\n",
       "   'just',\n",
       "   'need',\n",
       "   'leadership',\n",
       "   'worthy',\n",
       "   'of',\n",
       "   'our',\n",
       "   'nation',\n",
       "   'worthy',\n",
       "   'of',\n",
       "   'you',\n",
       "   'honest',\n",
       "   'leadership',\n",
       "   'to',\n",
       "   'bring',\n",
       "   'us',\n",
       "   'back',\n",
       "   'together',\n",
       "   'to',\n",
       "   'recover',\n",
       "   'from',\n",
       "   'this',\n",
       "   'pandemic',\n",
       "   'and',\n",
       "   'prepare',\n",
       "   'for',\n",
       "   'whatever',\n",
       "   'else',\n",
       "   'is',\n",
       "   'next',\n",
       "   'dr']},\n",
       " {'party': 'Democratic',\n",
       "  'words': ['heâ€™ll', 'love', 'you', 'with', 'all', 'of', 'his', 'heart']},\n",
       " {'party': 'Democratic',\n",
       "  'words': ['rhode',\n",
       "   'island',\n",
       "   'the',\n",
       "   'ocean',\n",
       "   'state',\n",
       "   'where',\n",
       "   'our',\n",
       "   'restaurant',\n",
       "   'and',\n",
       "   'fishing',\n",
       "   'industry',\n",
       "   'have',\n",
       "   'been',\n",
       "   'decimated',\n",
       "   'by',\n",
       "   'this',\n",
       "   'pandemic',\n",
       "   'are',\n",
       "   'lucky',\n",
       "   'to',\n",
       "   'have',\n",
       "   'a',\n",
       "   'governor',\n",
       "   'gina',\n",
       "   'raimondo',\n",
       "   'whose',\n",
       "   'program',\n",
       "   'lets',\n",
       "   'our',\n",
       "   'fishermen',\n",
       "   'sell',\n",
       "   'their',\n",
       "   'catches',\n",
       "   'directly',\n",
       "   'to',\n",
       "   'the',\n",
       "   'public',\n",
       "   'and',\n",
       "   'our',\n",
       "   'state',\n",
       "   'appetizer',\n",
       "   'calamari',\n",
       "   'is',\n",
       "   'available',\n",
       "   'in',\n",
       "   'all',\n",
       "   '50',\n",
       "   'states',\n",
       "   'the',\n",
       "   'calamari',\n",
       "   'comeback',\n",
       "   'state',\n",
       "   'of',\n",
       "   'rhode',\n",
       "   'island',\n",
       "   'casts',\n",
       "   '1',\n",
       "   'vote',\n",
       "   'for',\n",
       "   'bernie',\n",
       "   'sanders',\n",
       "   'and',\n",
       "   '34',\n",
       "   'votes',\n",
       "   'for',\n",
       "   'the',\n",
       "   'next',\n",
       "   'president',\n",
       "   'joe',\n",
       "   'biden']},\n",
       " {'party': 'Democratic',\n",
       "  'words': ['he',\n",
       "   'knows',\n",
       "   'what',\n",
       "   'itâ€™s',\n",
       "   'like',\n",
       "   'to',\n",
       "   'send',\n",
       "   'a',\n",
       "   'child',\n",
       "   'off',\n",
       "   'to',\n",
       "   'war']},\n",
       " {'party': 'Democratic', 'words': ['we', 'are', 'america']},\n",
       " {'party': 'Republican',\n",
       "  'words': ['trillions',\n",
       "   'of',\n",
       "   'dollars',\n",
       "   'were',\n",
       "   'repatriated',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'united',\n",
       "   'states',\n",
       "   'which',\n",
       "   'had',\n",
       "   'been',\n",
       "   'sitting',\n",
       "   'in',\n",
       "   'foreign',\n",
       "   'lands',\n",
       "   'for',\n",
       "   'far',\n",
       "   'too',\n",
       "   'long',\n",
       "   'once',\n",
       "   'again',\n",
       "   'america',\n",
       "   'became',\n",
       "   'the',\n",
       "   'envy',\n",
       "   'of',\n",
       "   'the',\n",
       "   'world',\n",
       "   'and',\n",
       "   'with',\n",
       "   'that',\n",
       "   'renewed',\n",
       "   'strength',\n",
       "   'came',\n",
       "   'a',\n",
       "   'leverage',\n",
       "   'the',\n",
       "   'president',\n",
       "   'demanded',\n",
       "   'that',\n",
       "   'our',\n",
       "   'allies',\n",
       "   'pay',\n",
       "   'their',\n",
       "   'fair',\n",
       "   'share',\n",
       "   'for',\n",
       "   'the',\n",
       "   'defense',\n",
       "   'of',\n",
       "   'a',\n",
       "   'western',\n",
       "   'world',\n",
       "   'my',\n",
       "   'father',\n",
       "   'rebuilt',\n",
       "   'the',\n",
       "   'mighty',\n",
       "   'american',\n",
       "   'military',\n",
       "   'adding',\n",
       "   'new',\n",
       "   'jets',\n",
       "   'aircraft',\n",
       "   'carriers',\n",
       "   'he',\n",
       "   'increased',\n",
       "   'wages',\n",
       "   'for',\n",
       "   'our',\n",
       "   'incredible',\n",
       "   'men',\n",
       "   'and',\n",
       "   'women',\n",
       "   'in',\n",
       "   'uniform',\n",
       "   'he',\n",
       "   'expanded',\n",
       "   'our',\n",
       "   'military',\n",
       "   'defense',\n",
       "   'budget',\n",
       "   'to',\n",
       "   '721',\n",
       "   'billion',\n",
       "   'per',\n",
       "   'year',\n",
       "   'america',\n",
       "   'was',\n",
       "   'no',\n",
       "   'longer',\n",
       "   'weak',\n",
       "   'in',\n",
       "   'the',\n",
       "   'eye',\n",
       "   'of',\n",
       "   'the',\n",
       "   'enemy',\n",
       "   'the',\n",
       "   'moment',\n",
       "   'president',\n",
       "   'trump',\n",
       "   'ordered',\n",
       "   'special',\n",
       "   'forces',\n",
       "   'kill',\n",
       "   'some',\n",
       "   'of',\n",
       "   'the',\n",
       "   'deadliest',\n",
       "   'terrorists',\n",
       "   'on',\n",
       "   'planet',\n",
       "   'the',\n",
       "   'day',\n",
       "   'the',\n",
       "   'mighty',\n",
       "   'moab',\n",
       "   'was',\n",
       "   'dropped',\n",
       "   'on',\n",
       "   'insurgent',\n",
       "   'camps',\n",
       "   'is',\n",
       "   'a',\n",
       "   'day',\n",
       "   'america',\n",
       "   'took',\n",
       "   'a',\n",
       "   'stance',\n",
       "   'in',\n",
       "   'never',\n",
       "   'be',\n",
       "   'defeated',\n",
       "   'by',\n",
       "   'the',\n",
       "   'enemy',\n",
       "   'albaghdadi',\n",
       "   'soleimani',\n",
       "   'dead',\n",
       "   'over',\n",
       "   'and',\n",
       "   'over',\n",
       "   'issue',\n",
       "   'after',\n",
       "   'issue',\n",
       "   'the',\n",
       "   'economy',\n",
       "   'the',\n",
       "   'wall',\n",
       "   'the',\n",
       "   'military',\n",
       "   'trade',\n",
       "   'deals',\n",
       "   'tax',\n",
       "   'cuts',\n",
       "   'supreme',\n",
       "   'court',\n",
       "   'justices',\n",
       "   'va',\n",
       "   'hospitals',\n",
       "   'prescription',\n",
       "   'drugs',\n",
       "   'school',\n",
       "   'choice',\n",
       "   'right',\n",
       "   'to',\n",
       "   'try',\n",
       "   'moving',\n",
       "   'the',\n",
       "   'embassy',\n",
       "   'to',\n",
       "   'jerusalem',\n",
       "   'peace',\n",
       "   'in',\n",
       "   'the',\n",
       "   'middle',\n",
       "   'east',\n",
       "   'neverending',\n",
       "   'wars',\n",
       "   'were',\n",
       "   'finally',\n",
       "   'ended',\n",
       "   'promises',\n",
       "   'made',\n",
       "   'and',\n",
       "   'promises',\n",
       "   'for',\n",
       "   'the',\n",
       "   'first',\n",
       "   'time',\n",
       "   'were',\n",
       "   'kept']}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "#tokens=convention_data[0]['words']\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "tokens=[]\n",
    "for row in convention_data:\n",
    "    tokens+=row['words']\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "engstopwords= stopwords.words(\"english\")\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff and word not in engstopwords:\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "                   \n",
    "    \"\"\"\n",
    "    ret_dict = dict()\n",
    "    text_words=text.split()\n",
    "    for feature_word in fw:\n",
    "        if feature_word in text_words:\n",
    "            ret_dict[feature_word]=True\n",
    "            \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'president': True, 'donald': True}\n"
     ]
    }
   ],
   "source": [
    "print(conv_features(\"donald is the president\",feature_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = []\n",
    "\n",
    "for row in convention_data:\n",
    "    party = row[\"party\"]\n",
    "    features = conv_features(\" \".join(row[\"words\"]), feature_words)\n",
    "    fset = (features, party)\n",
    "    featuresets.append(fset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_feature_probdist', '_label_probdist', '_labels', 'classify', 'classify_many', 'labels', 'most_informative_features', 'prob_classify', 'prob_classify_many', 'show_most_informative_features', 'train']\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "print(dir(classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "\n",
    "_Your observations to come._\n",
    "\n",
    "Democrats are talking a lot about climate and votes more than Republicans. And Republicans are talking a lot about China, enforcement, destroy, freedom, and crimes more than Democrats. Democrats focus more on climate issue 17.7 time than Republicans. Republicans most concern issue is China. Republicans talked about concern about China 25.8 time higher than Democrats. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with sqlite3.connect(\"congressional_data.db\") as db:\n",
    "    #cong_cur = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 49945 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results :\n",
    "    #generating variables and clean text process\n",
    "    candidate=row[0]\n",
    "    party=row[1]\n",
    "    text=row[2].decode('utf-8')\n",
    "    \n",
    "\n",
    "    text=text.lower()\n",
    "    text=text.replace('\\n',' ')\n",
    "    for punct in punctuation:\n",
    "        text=text.replace(punct,'')\n",
    "    \n",
    "    #adding words to convention data\n",
    "    \n",
    "    words=[]\n",
    "    for word in text.split():\n",
    "        if word not in engstopwords:\n",
    "            words.append(word)\n",
    "   \n",
    "    tweet_dict={'party':party, 'words':words,'candidate':candidate}\n",
    "    tweet_data.append(tweet_dict)\n",
    "    \n",
    "word_cutoff = 5\n",
    "\n",
    "tokens=[]\n",
    "for row in tweet_data:\n",
    "    tokens+=row['words']\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "engstopwords= stopwords.words(\"english\")\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff:\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: weâ€™re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: letâ€™s make even greater kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot thatâ€™s 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potusâ€™s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlaâ€™s 22 years eastside commitment amp saluted community leaders last nightâ€™s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for tweet, party in tweet_data_sample :\n",
    "for row in tweet_data_sample:\n",
    "    \n",
    "    \n",
    "    tweet=' '.join(row['words'])\n",
    "    party= row['party']\n",
    "    \n",
    "    features=conv_features(tweet,feature_words)\n",
    "    estimated_party= classifier.classify(features)\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, row in enumerate(tweet_data) :\n",
    "    tweet=' '.join(row['words'])\n",
    "    party= row['party']\n",
    "    features=conv_features(tweet,feature_words)\n",
    "    estimated_party= classifier.classify(features)\n",
    "      \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "   \n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3715, 'Democratic': 563}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4823, 'Democratic': 901})})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ \n",
    "\n",
    "\n",
    "From true positive observation, it shows that when republicans tweeted, 3715 were identified as Republican correctly. From false negative observation, 563 were incorrectly identified as Democratic. True positive rate (or sensitivity): TPR=TP/(TP+FN) so true positive rate, the accuracy is 88%. From democratic tweet, it shows that 4823 were correctly identified and 901 were incorrectly identified so true positive rate is 4823/4823+901 =  true positive accuracy rate is is 84%. In conclusion, Naive Bayes classification model performs well as true positive rate is closer to 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
